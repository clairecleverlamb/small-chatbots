{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS6l6KKxpFRm"
      },
      "source": [
        "###\n",
        "PIZZA EXAMPLE\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UYsZcEEcpKXl",
        "outputId": "94748d32-705a-459d-b2db-de8d48316510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.1 MB 8.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pydantic>=2.0\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 10.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting python-multipart>=0.0.9\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Collecting gradio-client==1.3.0\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[K     |████████████████████████████████| 318 kB 9.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting huggingface-hub>=0.19.3\n",
            "  Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 9.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: markupsafe~=2.0 in /Users/clrc/.local/lib/python3.9/site-packages (from gradio) (2.1.1)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /Users/clrc/.local/lib/python3.9/site-packages (from gradio) (3.6.1)\n",
            "Collecting fastapi<1.0\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 8.1 MB/s eta 0:00:011\n",
            "\u001b[?25hCollecting importlib-resources<7.0,>=1.3\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Collecting aiofiles<24.0,>=22.0\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /Users/clrc/.local/lib/python3.9/site-packages (from gradio) (1.23.4)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/clrc/.local/lib/python3.9/site-packages (from gradio) (1.5.0)\n",
            "Requirement already satisfied: packaging in /Users/clrc/.local/lib/python3.9/site-packages (from gradio) (21.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/clrc/.local/lib/python3.9/site-packages (from gradio) (9.2.0)\n",
            "Collecting anyio<5.0,>=3.0\n",
            "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 14.2 MB/s ta 0:00:01\n",
            "\u001b[?25hCollecting typer<1.0,>=0.12\n",
            "  Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 9.2 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting ffmpy\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Collecting orjson~=3.0\n",
            "  Downloading orjson-3.10.15-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (250 kB)\n",
            "\u001b[K     |████████████████████████████████| 250 kB 9.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting ruff>=0.2.2\n",
            "  Downloading ruff-0.11.2-py3-none-macosx_11_0_arm64.whl (10.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2 MB 9.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting typing-extensions~=4.0\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting tomlkit==0.12.0\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting httpx>=0.24.1\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 7.8 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: jinja2<4.0 in /Users/clrc/.local/lib/python3.9/site-packages (from gradio) (3.1.2)\n",
            "Collecting uvicorn>=0.14.0\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 5.9 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting urllib3~=2.0\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 16.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting semantic-version~=2.0\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from gradio) (6.0.1)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 14.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting websockets<13.0,>=10.0\n",
            "  Downloading websockets-12.0-cp39-cp39-macosx_11_0_arm64.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 9.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/clrc/.local/lib/python3.9/site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
            "Collecting exceptiongroup>=1.0.2\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 2.4 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: certifi in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (2021.10.8)\n",
            "Collecting httpcore==1.*\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 12.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: requests in /Users/clrc/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (4.62.3)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.7.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/clrc/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/clrc/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/clrc/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/clrc/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/clrc/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (4.37.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/clrc/.local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/clrc/.local/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio) (2022.4)\n",
            "Collecting pydantic-core==2.27.2\n",
            "  Downloading pydantic_core-2.27.2-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 127.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/clrc/.local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio) (8.0.3)\n",
            "Collecting rich>=10.11.0\n",
            "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 10.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting shellingham>=1.3.0\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 11.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/clrc/.local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.13.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/clrc/.local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.1.1)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 8.6 MB/s  eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: urllib3, typing-extensions, sniffio, mdurl, h11, exceptiongroup, requests, pydantic-core, markdown-it-py, httpcore, fsspec, filelock, anyio, annotated-types, websockets, starlette, shellingham, rich, pydantic, huggingface-hub, httpx, uvicorn, typer, tomlkit, semantic-version, ruff, python-multipart, pydub, orjson, importlib-resources, gradio-client, ffmpy, fastapi, aiofiles, gradio\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.12\n",
            "    Uninstalling urllib3-1.26.12:\n",
            "      Successfully uninstalled urllib3-1.26.12\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.7.4.3\n",
            "    Uninstalling typing-extensions-3.7.4.3:\n",
            "      Successfully uninstalled typing-extensions-3.7.4.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.28.1\n",
            "    Uninstalling requests-2.28.1:\n",
            "      Successfully uninstalled requests-2.28.1\n",
            "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 anyio-4.9.0 exceptiongroup-1.2.2 fastapi-0.115.11 ffmpy-0.5.0 filelock-3.18.0 fsspec-2025.3.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 huggingface-hub-0.29.3 importlib-resources-6.5.2 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.15 pydantic-2.10.6 pydantic-core-2.27.2 pydub-0.25.1 python-multipart-0.0.20 requests-2.32.3 rich-13.9.4 ruff-0.11.2 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.46.1 tomlkit-0.12.0 typer-0.15.2 typing-extensions-4.12.2 urllib3-2.3.0 uvicorn-0.34.0 websockets-12.0\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'transformers'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/clrc/smart-chatbots/datasets_labeling.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install gradio\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgr\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Initialize the zero-shot classifier (using facebook/bart-large-mnli)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m classifier \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mzero-shot-classification\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfacebook/bart-large-mnli\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the zero-shot classifier (using facebook/bart-large-mnli)\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Candidate labels now include an explicit \"out_of_scope\" option.\n",
        "CANDIDATE_LABELS = [\"greeting\", \"order_pizza\", \"menu_question\", \"out_of_scope\"]\n",
        "\n",
        "# Known pizza types for simple entity extraction simulation.\n",
        "PIZZA_TYPES = [\"pepperoni\", \"margherita\", \"vegetarian\", \"cheese\"]\n",
        "\n",
        "# Confidence threshold for deciding whether a prediction is reliable.\n",
        "THRESHOLD = 0.7\n",
        "\n",
        "def conversation_flow(user_input: str, state: dict):\n",
        "\n",
        "    if state is None:\n",
        "        state = {\"stage\": \"initial\", \"order\": None}\n",
        "\n",
        "    text = user_input.strip().lower()\n",
        "\n",
        "    # Check for immediate goodbye commands.\n",
        "    if \"bye\" in text or \"goodbye\" in text:\n",
        "        response = \"Goodbye! Have a great day. (Resetting conversation.)\"\n",
        "        state = {\"stage\": \"initial\", \"order\": None}\n",
        "        return response, state\n",
        "\n",
        "    # Use zero-shot classification to evaluate the input.\n",
        "    result = classifier(text, CANDIDATE_LABELS)\n",
        "    top_label = result[\"labels\"][0]\n",
        "    top_score = result[\"scores\"][0]\n",
        "\n",
        "    # If confidence is too low or out_of_scope is predicted, return a fallback message.\n",
        "    if top_score < THRESHOLD or top_label == \"out_of_scope\":\n",
        "        response = \"I'm not sure I understand. Could you please clarify your request?\"\n",
        "        return response, state\n",
        "\n",
        "    # Stage: initial\n",
        "    if state[\"stage\"] == \"initial\":\n",
        "        if top_label == \"greeting\":\n",
        "            response = \"Hello! How can I help you today? You can say something like 'I want to order a pizza.'\"\n",
        "            state[\"stage\"] = \"awaiting_intent\"\n",
        "        elif top_label == \"order_pizza\":\n",
        "            response = \"Great! What type of pizza would you like? (e.g., pepperoni, margherita)\"\n",
        "            state[\"stage\"] = \"awaiting_pizza_type\"\n",
        "        elif top_label == \"menu_question\":\n",
        "            response = \"Our menu includes pepperoni, margherita, vegetarian, and cheese pizzas. Would you like to place an order?\"\n",
        "            state[\"stage\"] = \"awaiting_intent\"\n",
        "        else:\n",
        "            response = \"I'm not sure I understand. Could you please clarify your request?\"\n",
        "            state[\"stage\"] = \"awaiting_intent\"\n",
        "        return response, state\n",
        "\n",
        "    # Stage: awaiting_intent\n",
        "    elif state[\"stage\"] == \"awaiting_intent\":\n",
        "        if top_label == \"order_pizza\":\n",
        "            response = \"Great! What type of pizza would you like? (e.g., pepperoni, margherita, vegetarian)\"\n",
        "            state[\"stage\"] = \"awaiting_pizza_type\"\n",
        "        elif top_label == \"menu_question\":\n",
        "            response = \"Our menu includes pepperoni, margherita, vegetarian, and cheese pizzas. Would you like to place an order?\"\n",
        "        elif top_label == \"greeting\":\n",
        "            response = \"Hi again! How can I assist you? If you'd like to order a pizza, just let me know.\"\n",
        "        else:\n",
        "            response = \"Could you please specify your request? For example, say 'I want to order a pizza.'\"\n",
        "        return response, state\n",
        "\n",
        "    # Stage: awaiting_pizza_type\n",
        "    elif state[\"stage\"] == \"awaiting_pizza_type\":\n",
        "        found_type = None\n",
        "        for pizza in PIZZA_TYPES:\n",
        "            if pizza in text:\n",
        "                found_type = pizza\n",
        "                break\n",
        "        if found_type:\n",
        "            response = f\"Got it! Your order for a {found_type} pizza has been placed. Thank you!\"\n",
        "            state[\"order\"] = found_type\n",
        "            state[\"stage\"] = \"order_confirmed\"\n",
        "        else:\n",
        "            response = \"I didn't catch the pizza type. Could you please specify (e.g., pepperoni, margherita, vegetarian, cheese)?\"\n",
        "        return response, state\n",
        "\n",
        "    # Stage: order_confirmed\n",
        "    elif state[\"stage\"] == \"order_confirmed\":\n",
        "        response = \"Your order is confirmed. If you'd like to order another pizza or have more questions, just let me know!\"\n",
        "        # Reset state for new orders.\n",
        "        state[\"stage\"] = \"awaiting_intent\"\n",
        "        state[\"order\"] = None\n",
        "        return response, state\n",
        "\n",
        "    # Fallback: reset conversation.\n",
        "    else:\n",
        "        response = \"I'm not sure how to proceed. Let's start over. How can I help you today?\"\n",
        "        state = {\"stage\": \"initial\", \"order\": None}\n",
        "        return response, state\n",
        "\n",
        "def chat_interface(user_message, history, state):\n",
        "\n",
        "    if state is None:\n",
        "        state = {\"stage\": \"initial\", \"order\": None}\n",
        "    response, state = conversation_flow(user_message, state)\n",
        "    history = history or []\n",
        "    history.append((user_message, response))\n",
        "    return history, state\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo_chat:\n",
        "    gr.Markdown(\"# Pizza Ordering Chatbot\")\n",
        "    gr.Markdown(\n",
        "        \"This chatbot helps you order pizza\"\n",
        "\n",
        "    )\n",
        "    chatbot = gr.Chatbot()\n",
        "    state = gr.State({\"stage\": \"initial\", \"order\": None})\n",
        "    txt = gr.Textbox(show_label=False, placeholder=\"Type your message here and press Enter\")\n",
        "    txt.submit(chat_interface, inputs=[txt, chatbot, state], outputs=[chatbot, state])\n",
        "\n",
        "\n",
        "demo_chat.launch()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "id": "PtGNVJUg7ZpK",
        "outputId": "0e625448-5d11-40f9-a96a-e49b345c3317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.50.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2 MB 5.9 MB/s eta 0:00:01    |█████████████████████           | 6.7 MB 3.6 MB/s eta 0:00:01     |████████████████████████████▋   | 9.1 MB 5.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[K     |████████████████████████████████| 487 kB 8.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 6.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tokenizers<0.22,>=0.21\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 5.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 9.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting safetensors>=0.4.3\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
            "\u001b[K     |████████████████████████████████| 418 kB 5.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/clrc/.local/lib/python3.9/site-packages (from transformers) (1.23.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: filelock in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/clrc/.local/lib/python3.9/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
            "Collecting multiprocess<0.70.17\n",
            "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 6.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tqdm>=4.27\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 10.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyarrow>=15.0.0\n",
            "  Downloading pyarrow-19.0.1-cp39-cp39-macosx_12_0_arm64.whl (30.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.7 MB 8.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.5.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
            "Collecting fsspec[http]<=2024.12.0,>=2023.1.0\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 16.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /Users/clrc/.local/lib/python3.9/site-packages (from datasets) (1.5.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/clrc/.local/lib/python3.9/site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->datasets) (4.12.2)\n",
            "Collecting dill<0.3.9,>=0.3.0\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 16.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/clrc/.local/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/clrc/.local/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/clrc/tensorflow-test/env/lib/python3.9/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/clrc/.local/lib/python3.9/site-packages (from pandas->datasets) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/clrc/.local/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/clrc/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tqdm, fsspec, dill, xxhash, pyarrow, multiprocess, tokenizers, safetensors, regex, datasets, transformers, evaluate\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "Successfully installed datasets-3.4.1 dill-0.3.8 evaluate-0.4.3 fsspec-2024.12.0 multiprocess-0.70.16 pyarrow-19.0.1 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.50.0 xxhash-3.5.0\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/clrc/smart-chatbots/datasets_labeling.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/clrc/smart-chatbots/datasets_labeling.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install transformers datasets evaluate\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "\n",
        "\n",
        "with open(\"example.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract texts and labels\n",
        "texts = [item[\"text\"] for item in data]\n",
        "labels_str = [item[\"label\"] for item in data]\n",
        "\n",
        "# Create a label mapping (string-to-integer) based on unique labels\n",
        "unique_labels = sorted(list(set(labels_str)))\n",
        "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "# Convert labels in the dataset to numeric form\n",
        "numeric_labels = [label2id[label] for label in labels_str]\n",
        "\n",
        "# Create a dictionary and then convert to a Hugging Face Dataset\n",
        "dataset_dict = {\"text\": texts, \"label\": numeric_labels}\n",
        "dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%) sets\n",
        "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "\n",
        "\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set the dataset format to PyTorch tensors (only include needed columns)\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "\n",
        "num_labels = len(unique_labels)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "\"\"\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluates at the end of each epoch.\n",
        "    save_strategy=\"epoch\",          # Saves the model at the end of each epoch.\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=1,\n",
        "    seed=42,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")\n",
        "\"\"\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",          # Save the model at the end of each epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=6,             # Increased epochs from 3 to 5\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=1,\n",
        "    seed=42,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")\n",
        "\n",
        "\n",
        "# Define the evaluation metric: accuracy\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", eval_results)\n",
        "\n",
        "save_directory = \"./pizza_model\"\n",
        "trainer.save_model(save_directory)\n",
        "print(f\"Model saved to {save_directory}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
